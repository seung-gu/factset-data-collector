# FactSet Data Collector

A unified Python package for extracting quarterly EPS (Earnings Per Share) estimates from FactSet Earnings Insight reports using OCR and image processing techniques.

## Overview

This project processes chart images containing S&P 500 quarterly EPS data and extracts quarter labels (e.g., Q1'14, Q2'15) and corresponding EPS values. The extracted data is saved in CSV format for further analysis.

### Motivation

Financial data providers (FactSet, Bloomberg, Investing.com, etc.) typically offer historical EPS data as **actual values**â€”once a quarter's earnings are reported, the estimate is overwritten with the actual figure. This creates a challenge for backtesting predictive models: using historical data means testing against information that was already reflected in stock prices at the time, making it difficult to evaluate the true predictive power of EPS estimates.

To address this, this project extracts **point-in-time EPS estimates** from historical FactSet Earnings Insight reports. By preserving the estimates as they appeared at each report date (before actual earnings were announced), a dataset can be built that accurately reflects what was known and expected at each point in time, enabling more meaningful backtesting and predictive analysis.

## Project Structure

```
factset-data-collector/
â”œâ”€â”€ src/factset_data_collector/
â”‚   â”œâ”€â”€ core/                        # Data collection
â”‚   â”‚   â”œâ”€â”€ downloader.py            # PDF download
â”‚   â”‚   â”œâ”€â”€ extractor.py             # Chart extraction
â”‚   â”‚   â””â”€â”€ ocr/                     # OCR processing
â”‚   â”‚       â”œâ”€â”€ processor.py         # Main pipeline
â”‚   â”‚       â”œâ”€â”€ google_vision_processor.py
â”‚   â”‚       â”œâ”€â”€ parser.py
â”‚   â”‚       â”œâ”€â”€ bar_classifier.py
â”‚   â”‚       â””â”€â”€ coordinate_matcher.py
â”‚   â”œâ”€â”€ analysis/                    # P/E ratio calculation
â”‚   â”‚   â””â”€â”€ pe_ratio.py
â”‚   â””â”€â”€ utils/                       # Cloud storage
â”‚       â”œâ”€â”€ cloudflare.py            # R2 operations
â”‚       â””â”€â”€ csv_storage.py           # CSV I/O
â”œâ”€â”€ scripts/data_collection/         # CLI scripts
â”œâ”€â”€ actions/workflow.py              # GitHub Actions
â””â”€â”€ pyproject.toml
```

## Installation

### Option 1: Install from Git (Recommended)
```bash
# Install with uv
uv pip install git+https://github.com/seung-gu/factset-data-collector.git

# Or with pip
pip install git+https://github.com/seung-gu/factset-data-collector.git
```

### Option 2: Local Development
```bash
# Clone repository
git clone https://github.com/seung-gu/factset-data-collector.git
cd factset-data-collector

# Install with uv
uv sync

# Or install in editable mode
uv pip install -e .
```

### Requirements

- **Google Cloud Vision API** (Required):
  - Create service account and download JSON key
  - Set `GOOGLE_APPLICATION_CREDENTIALS` environment variable
  - [Setup Guide](https://cloud.google.com/vision/docs/setup)

- **Cloudflare R2** (Optional - CI/CD only):
  - For GitHub Actions workflow only
  - Install: `uv sync --extra r2`

## Usage

### Python API

```python
from factset_data_collector import calculate_pe_ratio

# Calculate P/E ratios (auto-loads CSV from public URL)
pe_df = calculate_pe_ratio(
    price_data={'2024-01-15': 150.5, '2024-02-15': 152.3},
    type='forward'
)
print(pe_df)
```

**P/E Types:**
- `forward`: Q[1:5] - Next 4 quarters (skip current)
- `mix`: Q[0:4] - Current + next 3 quarters
- `trailing-like`: Q[-3:1] - Last 3 + current quarter

## Architecture

### Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ğŸ“¦ Storage Structure                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“¦ Public Bucket (R2_PUBLIC_BUCKET_NAME)                       â”‚
â”‚     â”œâ”€â”€ extracted_estimates.csv          â† Public URL (no auth) â”‚
â”‚     â””â”€â”€ extracted_estimates_confidence.csv                      â”‚
â”‚                                                                 â”‚
â”‚  ğŸ”’ Private Bucket (R2_BUCKET_NAME)                             â”‚
â”‚     â”œâ”€â”€ reports/*.pdf                    â† API key required     â”‚
â”‚     â””â”€â”€ estimates/*.png                  â† API key required     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### User Flow 1: API Users (Read-only)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python Script                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  from factset_data_collector import calculate_pe_ratio           â”‚
â”‚                                                                  â”‚
â”‚  pe_df = calculate_pe_ratio(                                     â”‚
â”‚      price_data={'2024-01-15': 150.5},                           â”‚
â”‚      type='forward'                                              â”‚
â”‚  )                                                               â”‚
â”‚     â”‚                                                            â”‚
â”‚     â”œâ”€ read_csv_from_cloud("extracted_estimates.csv")            â”‚
â”‚     â”‚      â”‚                                                     â”‚
â”‚     â”‚      â””â”€ GET https://pub-xxx.r2.dev/extracted_estimates.csv â”‚
â”‚     â”‚            â†‘                                               â”‚
â”‚     â”‚            â””â”€ âœ… No API key needed (public URL)            â”‚
â”‚     â”‚                                                            â”‚
â”‚     â””â”€ Calculate P/E ratios â†’ Return DataFrame                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- âœ… No API keys required
- âœ… Always loads latest data
- âœ… No local files needed

### User Flow 2: GitHub Actions Workflow (Read/Write)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Workflow Steps                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Step 1: Check last date                                        â”‚
â”‚     read_csv_from_cloud("extracted_estimates.csv")              â”‚
â”‚        â†’ GET public URL                                         â”‚
â”‚        â†’ Get last Report_Date                                   â”‚
â”‚                                                                 â”‚
â”‚  Step 2: Download new PDFs                                      â”‚
â”‚     download_pdfs(start_date=last_date)                         â”‚
â”‚        â†’ FactSet website                                        â”‚
â”‚        â†’ Save to local (temp)                                   â”‚
â”‚                                                                 â”‚
â”‚  Step 3: Extract charts                                         â”‚
â”‚     extract_charts(pdfs)                                        â”‚
â”‚        â†’ PDF â†’ PNG                                              â”‚
â”‚        â†’ Save to local (temp)                                   â”‚
â”‚                                                                 â”‚
â”‚  Step 4: Process images                                         â”‚
â”‚     process_images(directory)                                   â”‚
â”‚        â”œâ”€ read_csv_from_cloud() â† Load existing CSV             â”‚
â”‚        â”œâ”€ OCR processing                                        â”‚
â”‚        â”œâ”€ Merge existing + new data                             â”‚
â”‚        â””â”€ Return DataFrame (don't save locally)                 â”‚
â”‚                                                                 â”‚
â”‚  Step 5: Upload results                                         â”‚
â”‚     â”œâ”€ write_csv_to_cloud(df, "extracted_estimates.csv")        â”‚
â”‚     â”‚     â†’ PUT to public bucket (with API key)                 â”‚
â”‚     â”‚     â†’ Accessible via public URL                           â”‚
â”‚     â”‚                                                           â”‚
â”‚     â””â”€ upload_to_cloud(pdfs/pngs)                               â”‚
â”‚           â†’ PUT to private bucket (with API key)                â”‚
â”‚           â†’ Only accessible with API key                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- âœ… Reads from public URL (existing data)
- âœ… Writes to public bucket (CSV) with API key
- âœ… Writes to private bucket (PDF/PNG) with API key
- âœ… Appends new data (no overwrite)

### Environment Variables

```bash
# API Users
# â†’ No setup needed (public URL hardcoded)

# GitHub Actions Workflow
R2_BUCKET_NAME=factset-data          # ğŸ”’ Private bucket
R2_PUBLIC_BUCKET_NAME=factset-public # ğŸ“¦ Public bucket
R2_ACCOUNT_ID=xxx
R2_ACCESS_KEY_ID=xxx
R2_SECRET_ACCESS_KEY=xxx
CI=true
```

## Data Format

### Main CSV (`extracted_estimates.csv`)

| Report_Date | Q4'13 | Q1'14 | Q2'14 | ... |
|-------------|-------|-------|-------|-----|
| 2016-12-09  | 24.89 | 26.23 | 27.45 | ... |
| 2016-12-16  | 24.89 | 26.25 | 27.48 | ... |

- **Report_Date**: FactSet report date (YYYY-MM-DD)
- **Quarters**: EPS estimates in dollars
- **Public URL**: `https://pub-62707afd3ebb422aae744c63c49d36a0.r2.dev/extracted_estimates.csv`

### Confidence CSV

Same structure, contains OCR confidence scores (0-1).

## API Reference

### `calculate_pe_ratio(price_data, type='forward', output_csv=None)`

Calculate P/E ratios from EPS estimates.

**Parameters:**
- `price_data` (DataFrame | dict | None):
  - DataFrame: columns `Date`, `Price`
  - Dict: `{'2024-01-15': 150.5, ...}`
  - None: Returns template
- `type` (str): `'forward'`, `'mix'`, or `'trailing-like'`
- `output_csv` (Path, optional): Save results

**Returns:** DataFrame with P/E ratios

**Example:**
```python
from factset_data_collector import calculate_pe_ratio

pe_df = calculate_pe_ratio(
    price_data={'2024-01-15': 150.5},
    type='forward',
    output_csv='pe_ratios.csv'
)
```

## GitHub Actions

### Setup Secrets

Settings â†’ Secrets â†’ Actions:
```
GOOGLE_APPLICATION_CREDENTIALS_JSON
R2_BUCKET_NAME
R2_PUBLIC_BUCKET_NAME
R2_ACCOUNT_ID
R2_ACCESS_KEY_ID
R2_SECRET_ACCESS_KEY
```

### Workflow

- **Schedule**: Every Monday 00:00 UTC
- **Manual**: GitHub Actions tab
- **Steps**:
  1. Check last report date (public URL)
  2. Download new PDFs
  3. Extract charts â†’ Process with OCR
  4. Upload to cloud (PDFs/PNGs â†’ private, CSVs â†’ public)

## Recent Updates

### v0.3.0 (2025-11-19) - Cloud-First Architecture
- âœ… **Cloud-first design**: CSV data always from public URL
- âœ… **Two-bucket strategy**: Private (PDF/PNG) + Public (CSV)
- âœ… **Simplified codebase**: Removed local file logic
- âœ… **Code cleanup**: 45% reduction in csv_storage.py
- âœ… **Better organization**: Split functions by responsibility
- âœ… **API-focused**: Optimized for package users

### v0.2.0 (2025-11-19)
- Unified package structure
- Code reduction (33%)
- P/E ratio calculation module

## Technical Details

- **OCR**: Google Cloud Vision API (149 regions/image)
- **Text Matching**: Coordinate-based spatial algorithm
- **Bar Classification**: 3-method ensemble (100% agreement)
- **Confidence Score**: Bar classification (0.5) + consistency (0.5)

See [DEVELOPMENT_LOG.md](DEVELOPMENT_LOG.md) for detailed technical documentation.

## License

Educational and research purposes only.

## Acknowledgments

- FactSet (Earnings Insight reports)
- Google Cloud Vision API
- Cloudflare R2
